Q-1 What is the difference between the start() and run() method?
First, both methods are operated in general over the thread. So if we do use threadT1.start() then this method will look for the run() method to create a new thread. While in case of theadT1.run() method will be executed just likely the normal method by the “Main” thread without the creation of any new thread.
Note: If we do replace start() method with run() method then the entire program is carried by ‘main’ thread.
 Can we Overload run() method? What if we do not override the run() method?

We can overload the run() method but start() method will call no argument run() only. Hence, it will be of no help to us and is is considered as bad practice.
---------------------------------------------------------------------------------------------------------------------
Q-2 Can we Override the start() method?
Even if we override the start() method in the custom class then no initializations will be carried on by the Thread class for us. The run() method is also not called and even a new thread is also not created.
Thread Class vs Runnable Interface
If we extend the Thread class, our class cannot extend any other class because Java doesn’t support multiple inheritance. But, if we implement the Runnable interface, our class can still extend other base classes.
We can achieve basic functionality of a thread by extending Thread class because it provides some inbuilt methods like yield(), interrupt() etc. that are not available in Runnable interface.
Using runnable will give you an object that can be shared amongst multiple threads.

-------------------------------------------------------------------------------------------------------------------------

Thread lifecycle
yield,join -->thread methods --related to thead priority

wiat,notify ,notifyall -->object class methods --> related to lock on objects


New thread-->start--->Runnable state-->Running State-->acquire lock--> Running state-->blocked Threads--->join-->wiating
Q3)Join
If any executing thread t1 calls join() on t2 i.e; t2.join() immediately
 t1 will enter into waiting state until t2 completes its execution.
Giving a timeout within join(), will make the join() effect to be nullified after the specific timeout.



If t is a Thread object whose thread is currently executing, then t.join()
 will make sure that t is terminated before the next instruction is executed by the program—
 to maintain sequence of execution of thread.


Property	yield()	join()	sleep()
Purpose	If a thread wants to pass its execution to give chance to remaining threads of the same priority then we should go for yield()
If a thread wants to wait until completing of some other thread then we should go for join()
If a thread does not want to perform any operation for a particular amount of time, then it goes for sleep()

-------------------------------------------------------------------------------------------------------------------
Q4)Wait[used in synchronized  block]

Wait() should be called only from Synchronized context.	There is no need to call sleep() from Synchronized context.

Wait()	notify()
When wait() is called on a thread holding the monitor lock, it surrenders the monitor lock and enters the waiting state.
	When the notify() is called on a thread holding the monitor lock, it symbolizes that the thread is soon
	 going to surrender the lock.
There can be multiple threads in the waiting state at a time.
	One of the waiting threads is randomly selected and notified about the same.
	 The notified thread then exits the waiting state and enters the blocked state where it waits
	  till the previous thread has given up the lock and this thread has acquired it.
	   Once it acquires the lock, it enters the runnable state where it waits for CPU time and then it st

In java, synchronized methods and blocks allow only one thread to acquire the lock on a resource at a time.
 So, when wait() method is called by a thread, then it gives up the lock on that resource
  and goes to sleep until some other thread enters the same monitor and invokes the notify() or notifyAll() method.
--------------------------------------------------------------------------------------------------------------------
--------------------------------------------------------------------------------------------------------------
Q5) Future – Future blocking execution without error hanlling ->
ListenableFuture with error handling non blockingcompletable Future enhances with java 8 function chaining

Yes! CompletableFuture executes these tasks in a thread obtained from the global ForkJoinPool.commonPool().
listenablefuture – callback on complete and failure – aync process enabled
future – aync response will be locked till complete
Executor executor= new fixedthread();
Future<Object> future=Executore.submit(callable);

Callable vs runnable


java - Listenablefuture vs Completablefuture - Stack Overflow
https://www.callicoder.com/java-8-completablefuture-tutorial/


 -----------------------------------------------------------------------------------------------------------



wait() Method in Java With Examples - GeeksforGeeks
wait is used in synchronized context with notify and notify all
join is to pause execution of thread to die , to ensure sequence of execution of theread like t1.join ()t2).
Differences between wait() and join() methods in Java - GeeksforGeeks


Q5)Calling notify() wakes only one thread and calling notifyAll() wakes up all the threads on the same object. Calling both these methods does not give up the lock on the resource, rather its job is to wake up the threads that have been sent to the sleep state using wait() method.

Thread.wait();calling htread acquired lock, once done notify
-------------------------------------------_____________________________________________________
Q6yield() basically means that the thread is not doing anything particularly important
 and if any other threads or processes need to be run, they should run.
  Otherwise, the current thread will continue to run.

Deals with thread PRIORITY


`````````````````````````````````````````````````````````````````````````````````````

Q7)Deadlock

Avoid Nested Locks : This is the main reason for dead lock.
public static Object cacheLock = new Object();
  public static Object tableLock = new Object();
  ...
  public void oneMethod() {
    synchronized (cacheLock) {
      synchronized (tableLock) {
        doSomething();
      }
    }
  }
  public void anotherMethod() {
    synchronized (tableLock) {
      synchronized (cacheLock) {
        doSomethingElse();
      }
    }
  }

Q9) the transient keyword is used during serialization of Java object while volatile is related to the visibility of variables modified by multiple threads during concurrent programming.
The Volatile keyword is used to mark the JVM and thread to read its value from primary global memory and not utilize cached value present in the thread stack. It is used in concurrent programming in java.

Static vs volatile - . So the volatile variable will have only one main copy which will be updated by different threads and update made by one thread to the volatile variable will immediately reflect to the other Thread. – volatile update object value in cache
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~


Q)10
Frameworks take care of thread life cycle , creating thread pool , creating queue of tasks & submit for execution

ExecutorService exe=Executors.fixedThreadPoolExecutor(3);

exe.submit()/exe.execute();
Executor Service --uses fixed thread pool -->submit callable & Runnable tasks
Future<String> future = executorService.submit(() -> {
            Thread.sleep(2000);
            return "Hello, Future!";
        });
future.get() is blocking call -->need to wait till operation is completed --> error hanlding is not possible

Completable Future -->supplyAsync()uses forkjoin pool --> divide tasks & join concepts -- uses supplyAsyc()



CompletableFuture class implements the Future interface so
that we can use it as a Future implementation but with additional completion logic.


CompletableFuture<String> completableFuture
  = CompletableFuture.supplyAsync(() -> "Hello");

CompletableFuture<Void> future = completableFuture
  .thenAccept(s -> System.out.println("Computation returned: " + s));

future.get();

But hey, you can also create a Thread Pool and pass it to runAsync()
and supplyAsync() methods to let them execute their tasks in a thread obtained from your thread pool.

All the methods in the CompletableFuture API has two variants -
One which accepts an Executor as an argument and one which doesn’t -

// Variations of runAsync() and supplyAsync() methods
static CompletableFuture<Void>	runAsync(Runnable runnable)
static CompletableFuture<Void>	runAsync(Runnable runnable, Executor executor)
static <U> CompletableFuture<U>	supplyAsync(Supplier<U> supplier)
static <U> CompletableFuture<U>	supplyAsync(Supplier<U> supplier, Executor executor)




------------------------------------------------------------------------------------------------------
Q11)
Virtual threads in Java are a lightweight threading mechanism introduced in **Project Loom** (Java 19 preview, Java 21 stable). They provide an efficient way to handle concurrent tasks **without the overhead of traditional platform threads**. Here’s a breakdown:

### **🔹 What Are Virtual Threads?**
- They are **user-mode** threads that act like standard Java threads but are **not tied to OS threads**.
- Unlike traditional threads, they do **not block underlying OS threads** when waiting, making them highly scalable.
- They enable handling **massive numbers of concurrent tasks** efficiently.

### **🔹 Key Benefits**
1. **High Scalability** – Supports millions of concurrent tasks without exhausting system resources.
2. **Lower Memory Usage** – No need for heavy OS thread stacks, reducing memory overhead.
3. **Simplified Concurrency** – Works with Java’s existing threading model but with better performance.

### **🔹 How to Use Virtual Threads?**
You can create virtual threads using the `Executors.newVirtualThreadPerTaskExecutor()`:

```java
import java.util.concurrent.ExecutorService;
import java.util.concurrent.Executors;

public class VirtualThreadExample {
    public static void main(String[] args) {
        try (ExecutorService executor = Executors.newVirtualThreadPerTaskExecutor()) {
            for (int i = 0; i < 10; i++) {
                executor.submit(() -> {
                    System.out.println("Running in virtual thread: " + Thread.currentThread());
                });
            }
        }
    }
}
```

### **🔹 Difference: Virtual Threads vs Traditional Threads**
| Feature          | Virtual Threads | Platform Threads |
|-----------------|-----------------|------------------|
| **Thread Type**  | User-mode threads | OS-managed threads |
| **Performance** | Highly scalable | Limited scalability |
| **Memory Usage** | Lower | Higher |
| **Blocking** | Non-blocking OS threads | May block OS threads |

Virtual threads significantly improve **server performance, APIs, and microservices** that handle multiple concurrent requests.

Would you like help migrating existing code to use virtual threads? 🚀



Yes, virtual threads have a lifecycle similar to traditional threads, but with key differences in how they are managed by the JVM. Here's an overview of their lifecycle:
🔄 Virtual Thread Lifecycle
- Created – A virtual thread is created using Thread.ofVirtual() or an executor service (Executors.newVirtualThreadPerTaskExecutor()).




 How the OS Manages Conventional Threads
- The OS uses thread scheduling algorithms to determine which thread gets CPU time.
- Each platform thread is mapped to an OS thread, meaning it has its own stack, registers, and execution context.
- The OS manages context switching between threads, balancing CPU workload.
- OS-level threads can be preemptive or cooperative, depending on the scheduling strategy.
- The OS provides thread synchronization mechanisms (like mutexes and semaphores) to avoid race conditions.
🔹 Key Differences: JVM vs OS Thread Management
| Feature | JVM Threads (Platform Threads) | OS Thread Management |
| Memory Location | Heap Memory | Kernel/User Space |
| Thread Scheduling | Managed by JVM (on OS threads) | Managed by OS |
| Thread Mapping | One Java thread → One OS thread | Direct OS-level management |
| Concurrency Control | Locks & monitors (Java level) | Mutexes, semaphores (OS level) |


🧐 Impact of Virtual Threads
With virtual threads (Java 19+), threads no longer map one-to-one to OS threads. Instead, virtual threads allow millions of concurrent executions, bypassing OS thread limits.
Would you like an example illustrating this behavior in Java? 🚀



🔄 Virtual Threads & OS Threads
- Traditional Java Threads → Mapped one-to-one to OS threads, controlled by OS.
- Virtual Threads (Java 19+) → Not directly mapped to OS threads, scheduled by the JVM for high concurrency.
⚡ Key Takeaway
While Java abstracts many complexities via the JVM, the OS is always involved in process management, memory allocation, and thread execution.


 JVM & OS Interaction
- Process Management – The JVM itself is a native process created by the OS when you run a Java program (e.g., java MyApp).
- Memory Management – The OS allocates heap & stack memory to JVM processes, ensuring efficient execution.
- Thread Handling – Java platform threads are mapped to OS threads, meaning the OS scheduler controls thread execution.

-------------------------------------------------------------------------------------------------------------------------------

Q12) ReEntrant Lock


In Java, a reentrant lock is a synchronization mechanism that allows a thread to acquire the same lock multiple times without causing a deadlock.
### Basic Usage Example

Here’s a simple example demonstrating how to use `ReentrantLock`:

```java
import java.util.concurrent.locks.ReentrantLock;

public class ReentrantLockExample {
    private final ReentrantLock lock = new ReentrantLock();

    public void method() {
        lock.lock(); // Acquire the lock
        try {
            // Critical section
            System.out.println(Thread.currentThread().getName() + " is in the method.");
            // Call another method that also tries to acquire the lock
            anotherMethod();
        } finally {
            lock.unlock(); // Always unlock in a finally block
        }
    }

    public void anotherMethod() {
        lock.lock(); // Re-acquire the lock
        try {
            // Critical section
            System.out.println(Thread.currentThread().getName() + " is in anotherMethod.");
        } finally {
            lock.unlock(); // Always unlock in a finally block
        }
    }

    public static void main(String[] args) {
        ReentrantLockExample example = new ReentrantLockExample();

        // Create threads that will call the method
        Thread thread1 = new Thread(example::method, "Thread-1");
        Thread thread2 = new Thread(example::method, "Thread-2");

        thread1.start();
        thread2.start();
    }
}
```

### Explanation:
1. **Lock Acquisition**: The `lock()` method is called to acquire the lock. If the lock is already held by another thread, the current thread will block until the lock is available.
2. **Reentrancy**: The same thread can call `anotherMethod()` while holding the lock, and it will successfully acquire the lock again.
3. **Unlocking**: It’s crucial to call `unlock()` in a `finally` block to ensure that the lock is released even if an exception occurs.

### Fairness
You can create a fair `ReentrantLock` by passing `true` to the constructor:

```java
ReentrantLock fairLock = new ReentrantLock(true);
```

This ensures that threads acquire the lock in the order they requested it.

### Conclusion
`ReentrantLock` is a powerful tool for managing concurrency in Java applications. It provides more flexibility than synchronized blocks, especially in complex scenarios where you need to manage multiple conditions or require fair access to resources.




---------------------------------------------------------------------------------------------------------------------------------------------------------------

Q13)


PriorityQueue and BlockingQueue are two distinct types of queues in Java, each serving different purposes, particularly in concurrent programming.
### 1. `java.util.PriorityQueue`

A `PriorityQueue` is an **unbounded priority queue** based on a priority heap.
Elements of the priority queue are ordered according to their natural ordering, or by a `Comparator` provided at queue construction time,
 depending on which constructor is used.

**Key Characteristics:**

* **Priority-Based Ordering:** Elements are retrieved based on their priority, not necessarily in the order they were inserted (FIFO).
* **Unbounded (Logically):** It can grow as large as needed, limited only by available memory.
* **Not Thread-Safe:** It's *not* designed for concurrent access by multiple threads. If you need a thread-safe priority queue, you'd typically use `PriorityBlockingQueue` (discussed later) or wrap `PriorityQueue` with synchronization mechanisms.
* **Heap-Based:** Internally, it uses a min-heap data structure to efficiently manage priorities.
 The smallest element (highest priority in a min-heap) is always at the root.

**Example:**

Let's say we have a list of tasks with different priority levels. We want to process the highest priority tasks first.

```java
import java.util.Comparator;
import java.util.PriorityQueue;

class Task {
    private String name;
    private int priority; // Lower number indicates higher priority

    public Task(String name, int priority) {
        this.name = name;
        this.priority = priority;
    }

    public String getName() {
        return name;
    }

    public int getPriority() {
        return priority;
    }

    @Override
    public String toString() {
        return "Task{" +
               "name='" + name + '\'' +
               ", priority=" + priority +
               '}';
    }
}

public class PriorityQueueExample {
    public static void main(String[] args) {
        // Create a PriorityQueue for Tasks
        // We provide a Comparator to define priority: lower 'priority' value means higher priority
        PriorityQueue<Task> taskQueue = new PriorityQueue<>(
            Comparator.comparingInt(Task::getPriority)
        );

        // Add tasks to the queue
        taskQueue.offer(new Task("Write documentation", 3));
        taskQueue.offer(new Task("Fix critical bug", 1));
        taskQueue.offer(new Task("Refactor legacy code", 4));
        taskQueue.offer(new Task("Implement new feature", 2));
        taskQueue.offer(new Task("Attend team meeting", 1)); // Another high-priority task

        System.out.println("Processing tasks in priority order:");

        // Process tasks until the queue is empty
        while (!taskQueue.isEmpty()) {
            Task task = taskQueue.poll(); // Retrieves and removes the highest priority task
            System.out.println("Processing: " + task);
        }
    }
}
```

**Output:**

```
Processing tasks in priority order:
Processing: Task{name='Fix critical bug', priority=1}
Processing: Task{name='Attend team meeting', priority=1}
Processing: Task{name='Implement new feature', priority=2}
Processing: Task{name='Write documentation', priority=3}
Processing: Task{name='Refactor legacy code', priority=4}
```

Notice how "Fix critical bug" and "Attend team meeting" (both priority 1) were processed first, followed by priority 2, 3, and 4. The order of tasks with the same priority is not guaranteed.

### 2. `java.util.concurrent.BlockingQueue`

`BlockingQueue` is an interface that extends `java.util.Queue`. It's designed for use in **producer-consumer scenarios** and other concurrent applications. The "blocking" aspect means that operations can wait (block) if the queue is empty or full.

**Key Characteristics:**

* **Thread-Safe:** All implementations of `BlockingQueue` are thread-safe. They handle synchronization internally.
* **Blocking Operations:**
    * **Insertion (`put()`):** If the queue is full, `put()` will block until space becomes available.
    * **Retrieval (`take()`):** If the queue is empty, `take()` will block until an element becomes available.
* **Non-Blocking Alternatives:** It also provides non-blocking operations like `offer()`, `poll()`, `add()`, and `remove()`, which return `false` or `null` if the operation cannot be performed immediately, or throw an exception.
* **Bounded or Unbounded:** Implementations can be bounded (fixed capacity) or unbounded (capacity limited only by memory).
* **Common Implementations:**
    * `ArrayBlockingQueue`: Bounded, backed by an array, FIFO.
    * `LinkedBlockingQueue`: Optionally bounded (default unbounded), backed by a linked list, FIFO.
    * `PriorityBlockingQueue`: Unbounded, a thread-safe version of `PriorityQueue`.
    * `DelayQueue`: Stores elements that can only be retrieved after a given delay.
    * `SynchronousQueue`: A queue of size one, where each insert operation must wait for a corresponding remove operation, and vice versa.

**Example: Producer-Consumer using `ArrayBlockingQueue`**

This classic example demonstrates how `BlockingQueue` facilitates communication between a producer thread (adding items) and a consumer thread (removing items).

```java
import java.util.concurrent.ArrayBlockingQueue;
import java.util.concurrent.BlockingQueue;

// Producer Thread
class Producer implements Runnable {
    private BlockingQueue<Integer> queue;
    private int startValue;

    public Producer(BlockingQueue<Integer> queue, int startValue) {
        this.queue = queue;
        this.startValue = startValue;
    }

    @Override
    public void run() {
        for (int i = 0; i < 5; i++) {
            int value = startValue + i;
            try {
                System.out.println(Thread.currentThread().getName() + " producing: " + value);
                queue.put(value); // Blocks if the queue is full
                Thread.sleep(500); // Simulate some work
            } catch (InterruptedException e) {
                Thread.currentThread().interrupt();
                System.out.println(Thread.currentThread().getName() + " interrupted.");
            }
        }
    }
}

// Consumer Thread
class Consumer implements Runnable {
    private BlockingQueue<Integer> queue;

    public Consumer(BlockingQueue<Integer> queue) {
        this.queue = queue;
    }

    @Override
    public void run() {
        while (true) {
            try {
                Integer value = queue.take(); // Blocks if the queue is empty
                System.out.println(Thread.currentThread().getName() + " consuming: " + value);
                Thread.sleep(1000); // Simulate some work
            } catch (InterruptedException e) {
                Thread.currentThread().interrupt();
                System.out.println(Thread.currentThread().getName() + " interrupted.");
                break; // Exit loop if interrupted
            }
        }
    }
}

public class BlockingQueueExample {
    public static void main(String[] args) throws InterruptedException {
        // Create an ArrayBlockingQueue with a capacity of 5
        BlockingQueue<Integer> sharedQueue = new ArrayBlockingQueue<>(5);

        // Create producer and consumer threads
        Thread producerThread1 = new Thread(new Producer(sharedQueue, 100), "Producer-1");
        Thread producerThread2 = new Thread(new Producer(sharedQueue, 200), "Producer-2");
        Thread consumerThread1 = new Thread(new Consumer(sharedQueue), "Consumer-1");
        Thread consumerThread2 = new Thread(new Consumer(sharedQueue), "Consumer-2");


        // Start the threads
        producerThread1.start();
        producerThread2.start();
        consumerThread1.start();
        consumerThread2.start();

        // Give some time for threads to execute
        Thread.sleep(7000);

        // Interrupt consumers to stop them (they would otherwise run indefinitely)
        consumerThread1.interrupt();
        consumerThread2.interrupt();

        System.out.println("Main thread finished.");
    }
}
```

**Partial Output (will vary due to thread scheduling):**

```
Producer-1 producing: 100
Consumer-1 consuming: 100
Producer-2 producing: 200
Producer-1 producing: 101
Consumer-2 consuming: 200
Producer-2 producing: 201
Producer-1 producing: 102
Consumer-1 consuming: 101
Producer-2 producing: 202
Producer-1 producing: 103
Consumer-2 consuming: 201
Producer-2 producing: 203
Producer-1 producing: 104
Consumer-1 consuming: 102
Consumer-2 consuming: 202
Consumer-1 consuming: 103
Consumer-2 consuming: 203
Consumer-1 consuming: 104
Consumer-1 interrupted.
Consumer-2 interrupted.
Main thread finished.
```

In this output, you can observe:

* Producers add elements, and consumers remove them.
* When the queue is full (capacity 5), producers will pause (`put()` blocks) until a consumer removes an element.
* When the queue is empty, consumers will pause (`take()` blocks) until a producer adds an element.
* Multiple producers and consumers can safely interact with the shared queue.

### When to Use Which:

* **`PriorityQueue`**:
    * When you need to process elements based on their priority, not their insertion order.
    * When you are in a single-threaded environment or you are handling synchronization yourself (e.g., using `Collections.synchronizedList`).
    * Examples: Task scheduling where higher-priority tasks need to be executed first, event queues in simulations, A* search algorithm.

* **`BlockingQueue` (and its implementations like `ArrayBlockingQueue`, `LinkedBlockingQueue`, `PriorityBlockingQueue`)**:
    * When you are dealing with concurrent access from multiple threads (producer-consumer patterns).
    * When you need threads to block and wait for elements to be available or for space to become available.
    * When you need a thread-safe, robust solution for inter-thread communication.
    * `PriorityBlockingQueue` specifically combines the thread-safety and blocking behavior of `BlockingQueue` with the priority-based ordering of `PriorityQueue`.
    * Examples: Thread pools, message queues, work stealing patterns, data processing pipelines.

Understanding the difference between `PriorityQueue` (non-thread-safe, priority-based) and `BlockingQueue` (thread-safe, blocking operations) is crucial for writing efficient and correct concurrent Java applications.
